{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn to execute\n",
    "\n",
    "``` bash\n",
    "\n",
    "Input: \"535+61\" Output: \"596\"\n",
    "\n",
    "```\n",
    "\n",
    "Inspired by learn to fizzbuzz: http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.engine.training import slice_X\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    '''\n",
    "    Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    '''\n",
    "    def __init__(self, chars, maxlen):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def encode(self, C, maxlen=None):\n",
    "        maxlen = maxlen if maxlen else self.maxlen\n",
    "        X = np.zeros((maxlen, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            X[i, self.char_indices[c]] = 1\n",
    "        return X\n",
    "\n",
    "    def decode(self, X, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            X = X.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = False\n",
    "# Try replacing GRU, or SimpleRNN\n",
    "RNN = recurrent.GRU\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars, MAXLEN)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "CPU times: user 4.62 s, sys: 36.2 ms, total: 4.66 s\n",
      "Wall time: 4.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Generating random  numbers to perofrm addition on\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that X+Y == Y+X (hence the sorting)\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if INVERT:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "#We now have 50000 examples of addition, each exaple contains the addition between two numbers\n",
    "#Each example contains the first number followed by '+' operand followed by the second number \n",
    "#examples - 85+96, 353+551, 6+936\n",
    "#The answers to the additon operation are stored in expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000\n",
      "503+8   511 \n"
     ]
    }
   ],
   "source": [
    "print(len(questions), len(expected))\n",
    "print(questions[0], expected[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "CPU times: user 337 ms, sys: 9.56 ms, total: 346 ms\n",
      "Wall time: 350 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#The above questions and answers are going to be one hot encoded, \n",
    "#before training.\n",
    "#The encoded values will be used to train the model\n",
    "#The maximum length of a question can be 7 \n",
    "#(3 digits followed by '+' followed by 3 digits)\n",
    "#The maximum length of an answer can be 4 \n",
    "#(Since the addition of 3 digits yields either a 3 digit number or a 4\n",
    "#4 digit number)\n",
    "\n",
    "#Now for training each number or operand is going to be one hot encode below\n",
    "#In one hot encode there are 12 possibilities '0123456789+ ' (The last one is a space)\n",
    "#Since we assume a maximum of 3 digit numbers, a two digit number is taken as space with two digts, or \n",
    "#a single digit number as two spaces with a number\n",
    "\n",
    "#So for questions we get 7 rows since the max possible length is 7, and each row has a length of 12 because it will\n",
    "#be one hot encoded with True and False, depending on the character(any one of the number, '+' operand, or space)\n",
    "#will be stored  in X_train and X_val\n",
    "#The 4th position in(1,2,3,4,5,6,7) will indicate the one hot encoding of the '+' operand\n",
    "\n",
    "##So for questions we get 4 rows since the max possible length is 4, and each row has a length of 12 because it will\n",
    "#be one hot encoded with True and False, depending on the character(any one of the number, '+' operand, or space)\n",
    "#will be stored  in y_train and y_val\n",
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    X[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, maxlen=DIGITS + 1)\n",
    "\n",
    "# Shuffle (X, y) in unison as the later parts of X will almost all be larger digits\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over\n",
    "split_at = len(X) - len(X) / 10\n",
    "(X_train, X_val) = (slice_X(X, 0, split_at), slice_X(X, split_at))\n",
    "(y_train, y_val) = (y[:split_at], y[split_at:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 7, 12) (50000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False False False  True False False False False False]\n",
      " [False False False False False False False False  True False False False]\n",
      " [False  True False False False False False False False False False False]\n",
      " [False False False False False  True False False False False False False]\n",
      " [False False False False False False False  True False False False False]\n",
      " [False False False False False False False False False False False  True]\n",
      " [ True False False False False False False False False False False False]]\n",
      "[[False False False False False False  True False False False False False]\n",
      " [False False  True False False False False False False False False False]\n",
      " [False False False False False False False  True False False False False]\n",
      " [ True False False False False False False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "CPU times: user 120 ms, sys: 33.6 ms, total: 154 ms\n",
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Training the model with the encoded inputs\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE\n",
    "# note: in a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, nb_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# For the decoder's input, we repeat the encoded input for each time step\n",
    "model.add(RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer\n",
    "for _ in range(LAYERS):\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# For each of step of the output sequence, decide which character should be chosen\n",
    "model.add(TimeDistributed(Dense(len(chars))))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, RemoteMonitor\n",
    "\n",
    "remote = RemoteMonitor(root='http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/124\n",
      "Epoch 00000: val_loss improved from inf to 1.79681, saving model to learn-to-execute-progress-dl\n",
      "13s - loss: 1.8327 - acc: 0.3403 - val_loss: 1.7968 - val_acc: 0.3482\n",
      "Epoch 2/124\n",
      "Epoch 00001: val_loss improved from 1.79681 to 1.46504, saving model to learn-to-execute-progress-dl\n",
      "13s - loss: 1.5827 - acc: 0.4130 - val_loss: 1.4650 - val_acc: 0.4511\n",
      "Epoch 3/124\n",
      "Epoch 00002: val_loss improved from 1.46504 to 1.29585, saving model to learn-to-execute-progress-dl\n",
      "13s - loss: 1.3693 - acc: 0.4862 - val_loss: 1.2959 - val_acc: 0.5150\n",
      "Epoch 4/124\n",
      "Epoch 00003: val_loss improved from 1.29585 to 1.12576, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 1.2009 - acc: 0.5486 - val_loss: 1.1258 - val_acc: 0.5745\n",
      "Epoch 5/124\n",
      "Epoch 00004: val_loss improved from 1.12576 to 0.99550, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 1.0570 - acc: 0.6034 - val_loss: 0.9955 - val_acc: 0.6305\n",
      "Epoch 6/124\n",
      "Epoch 00005: val_loss improved from 0.99550 to 0.91201, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.9407 - acc: 0.6485 - val_loss: 0.9120 - val_acc: 0.6471\n",
      "Epoch 7/124\n",
      "Epoch 00006: val_loss improved from 0.91201 to 0.78219, saving model to learn-to-execute-progress-dl\n",
      "13s - loss: 0.8259 - acc: 0.6903 - val_loss: 0.7822 - val_acc: 0.6984\n",
      "Epoch 8/124\n",
      "Epoch 00007: val_loss improved from 0.78219 to 0.66774, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.6974 - acc: 0.7364 - val_loss: 0.6677 - val_acc: 0.7452\n",
      "Epoch 9/124\n",
      "Epoch 00008: val_loss improved from 0.66774 to 0.57354, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.5796 - acc: 0.7848 - val_loss: 0.5735 - val_acc: 0.7811\n",
      "Epoch 10/124\n",
      "Epoch 00009: val_loss improved from 0.57354 to 0.47164, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.4877 - acc: 0.8229 - val_loss: 0.4716 - val_acc: 0.8289\n",
      "Epoch 11/124\n",
      "Epoch 00010: val_loss improved from 0.47164 to 0.41165, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.4052 - acc: 0.8546 - val_loss: 0.4117 - val_acc: 0.8429\n",
      "Epoch 12/124\n",
      "Epoch 00011: val_loss improved from 0.41165 to 0.33052, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.3376 - acc: 0.8816 - val_loss: 0.3305 - val_acc: 0.8824\n",
      "Epoch 13/124\n",
      "Epoch 00012: val_loss improved from 0.33052 to 0.25652, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.2841 - acc: 0.9027 - val_loss: 0.2565 - val_acc: 0.9169\n",
      "Epoch 14/124\n",
      "Epoch 00013: val_loss improved from 0.25652 to 0.22634, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.2410 - acc: 0.9199 - val_loss: 0.2263 - val_acc: 0.9264\n",
      "Epoch 15/124\n",
      "Epoch 00014: val_loss improved from 0.22634 to 0.21084, saving model to learn-to-execute-progress-dl\n",
      "13s - loss: 0.2071 - acc: 0.9327 - val_loss: 0.2108 - val_acc: 0.9287\n",
      "Epoch 16/124\n",
      "Epoch 00015: val_loss improved from 0.21084 to 0.16789, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.1793 - acc: 0.9434 - val_loss: 0.1679 - val_acc: 0.9488\n",
      "Epoch 17/124\n",
      "Epoch 00016: val_loss improved from 0.16789 to 0.14320, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.1595 - acc: 0.9506 - val_loss: 0.1432 - val_acc: 0.9570\n",
      "Epoch 18/124\n",
      "Epoch 00017: val_loss did not improve\n",
      "14s - loss: 0.1424 - acc: 0.9572 - val_loss: 0.1809 - val_acc: 0.9351\n",
      "Epoch 19/124\n",
      "Epoch 00018: val_loss improved from 0.14320 to 0.11843, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.1259 - acc: 0.9621 - val_loss: 0.1184 - val_acc: 0.9640\n",
      "Epoch 20/124\n",
      "Epoch 00019: val_loss improved from 0.11843 to 0.10680, saving model to learn-to-execute-progress-dl\n",
      "13s - loss: 0.1149 - acc: 0.9659 - val_loss: 0.1068 - val_acc: 0.9665\n",
      "Epoch 21/124\n",
      "Epoch 00020: val_loss did not improve\n",
      "13s - loss: 0.1040 - acc: 0.9697 - val_loss: 0.1125 - val_acc: 0.9621\n",
      "Epoch 22/124\n",
      "Epoch 00021: val_loss did not improve\n",
      "14s - loss: 0.0949 - acc: 0.9721 - val_loss: 0.2449 - val_acc: 0.9205\n",
      "Epoch 23/124\n",
      "Epoch 00022: val_loss did not improve\n",
      "14s - loss: 0.0886 - acc: 0.9744 - val_loss: 0.1112 - val_acc: 0.9623\n",
      "Epoch 24/124\n",
      "Epoch 00023: val_loss improved from 0.10680 to 0.10100, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0813 - acc: 0.9764 - val_loss: 0.1010 - val_acc: 0.9664\n",
      "Epoch 25/124\n",
      "Epoch 00024: val_loss did not improve\n",
      "14s - loss: 0.0764 - acc: 0.9780 - val_loss: 0.2463 - val_acc: 0.9182\n",
      "Epoch 26/124\n",
      "Epoch 00025: val_loss improved from 0.10100 to 0.09864, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0677 - acc: 0.9804 - val_loss: 0.0986 - val_acc: 0.9661\n",
      "Epoch 27/124\n",
      "Epoch 00026: val_loss improved from 0.09864 to 0.07303, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0669 - acc: 0.9807 - val_loss: 0.0730 - val_acc: 0.9778\n",
      "Epoch 28/124\n",
      "Epoch 00027: val_loss improved from 0.07303 to 0.06012, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0636 - acc: 0.9820 - val_loss: 0.0601 - val_acc: 0.9806\n",
      "Epoch 29/124\n",
      "Epoch 00028: val_loss did not improve\n",
      "14s - loss: 0.0570 - acc: 0.9838 - val_loss: 0.0697 - val_acc: 0.9757\n",
      "Epoch 30/124\n",
      "Epoch 00029: val_loss did not improve\n",
      "14s - loss: 0.0547 - acc: 0.9848 - val_loss: 0.0933 - val_acc: 0.9684\n",
      "Epoch 31/124\n",
      "Epoch 00030: val_loss did not improve\n",
      "14s - loss: 0.0529 - acc: 0.9847 - val_loss: 0.0693 - val_acc: 0.9755\n",
      "Epoch 32/124\n",
      "Epoch 00031: val_loss did not improve\n",
      "14s - loss: 0.0484 - acc: 0.9864 - val_loss: 0.0912 - val_acc: 0.9697\n",
      "Epoch 33/124\n",
      "Epoch 00032: val_loss did not improve\n",
      "14s - loss: 0.0477 - acc: 0.9865 - val_loss: 0.0610 - val_acc: 0.9787\n",
      "Epoch 34/124\n",
      "Epoch 00033: val_loss improved from 0.06012 to 0.05172, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0438 - acc: 0.9874 - val_loss: 0.0517 - val_acc: 0.9830\n",
      "Epoch 35/124\n",
      "Epoch 00034: val_loss did not improve\n",
      "14s - loss: 0.0436 - acc: 0.9878 - val_loss: 0.1201 - val_acc: 0.9629\n",
      "Epoch 36/124\n",
      "Epoch 00035: val_loss did not improve\n",
      "13s - loss: 0.0417 - acc: 0.9882 - val_loss: 0.0598 - val_acc: 0.9805\n",
      "Epoch 37/124\n",
      "Epoch 00036: val_loss improved from 0.05172 to 0.04664, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0401 - acc: 0.9890 - val_loss: 0.0466 - val_acc: 0.9846\n",
      "Epoch 38/124\n",
      "Epoch 00037: val_loss did not improve\n",
      "14s - loss: 0.0386 - acc: 0.9890 - val_loss: 0.0547 - val_acc: 0.9808\n",
      "Epoch 39/124\n",
      "Epoch 00038: val_loss did not improve\n",
      "13s - loss: 0.0341 - acc: 0.9901 - val_loss: 0.0626 - val_acc: 0.9787\n",
      "Epoch 40/124\n",
      "Epoch 00039: val_loss did not improve\n",
      "14s - loss: 0.0356 - acc: 0.9901 - val_loss: 0.0615 - val_acc: 0.9818\n",
      "Epoch 41/124\n",
      "Epoch 00040: val_loss improved from 0.04664 to 0.03983, saving model to learn-to-execute-progress-dl\n",
      "13s - loss: 0.0335 - acc: 0.9904 - val_loss: 0.0398 - val_acc: 0.9865\n",
      "Epoch 42/124\n",
      "Epoch 00041: val_loss did not improve\n",
      "14s - loss: 0.0348 - acc: 0.9905 - val_loss: 0.0488 - val_acc: 0.9843\n",
      "Epoch 43/124\n",
      "Epoch 00042: val_loss improved from 0.03983 to 0.03864, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0302 - acc: 0.9914 - val_loss: 0.0386 - val_acc: 0.9873\n",
      "Epoch 44/124\n",
      "Epoch 00043: val_loss improved from 0.03864 to 0.03863, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0318 - acc: 0.9911 - val_loss: 0.0386 - val_acc: 0.9866\n",
      "Epoch 45/124\n",
      "Epoch 00044: val_loss improved from 0.03863 to 0.03768, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0300 - acc: 0.9918 - val_loss: 0.0377 - val_acc: 0.9876\n",
      "Epoch 46/124\n",
      "Epoch 00045: val_loss did not improve\n",
      "14s - loss: 0.0305 - acc: 0.9919 - val_loss: 0.0465 - val_acc: 0.9845\n",
      "Epoch 47/124\n",
      "Epoch 00046: val_loss did not improve\n",
      "14s - loss: 0.0289 - acc: 0.9917 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 48/124\n",
      "Epoch 00047: val_loss did not improve\n",
      "14s - loss: 0.0269 - acc: 0.9927 - val_loss: 0.0769 - val_acc: 0.9757\n",
      "Epoch 49/124\n",
      "Epoch 00048: val_loss did not improve\n",
      "14s - loss: 0.0264 - acc: 0.9924 - val_loss: 0.0386 - val_acc: 0.9863\n",
      "Epoch 50/124\n",
      "Epoch 00049: val_loss did not improve\n",
      "14s - loss: 0.0265 - acc: 0.9928 - val_loss: 0.0675 - val_acc: 0.9795\n",
      "Epoch 51/124\n",
      "Epoch 00050: val_loss did not improve\n",
      "14s - loss: 0.0245 - acc: 0.9933 - val_loss: 0.0465 - val_acc: 0.9837\n",
      "Epoch 52/124\n",
      "Epoch 00051: val_loss did not improve\n",
      "13s - loss: 0.0259 - acc: 0.9929 - val_loss: 0.0515 - val_acc: 0.9845\n",
      "Epoch 53/124\n",
      "Epoch 00052: val_loss did not improve\n",
      "14s - loss: 0.0233 - acc: 0.9935 - val_loss: 0.0512 - val_acc: 0.9835\n",
      "Epoch 54/124\n",
      "Epoch 00053: val_loss improved from 0.03768 to 0.03586, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0256 - acc: 0.9929 - val_loss: 0.0359 - val_acc: 0.9873\n",
      "Epoch 55/124\n",
      "Epoch 00054: val_loss did not improve\n",
      "14s - loss: 0.0237 - acc: 0.9933 - val_loss: 0.0453 - val_acc: 0.9842\n",
      "Epoch 56/124\n",
      "Epoch 00055: val_loss improved from 0.03586 to 0.03028, saving model to learn-to-execute-progress-dl\n",
      "14s - loss: 0.0220 - acc: 0.9941 - val_loss: 0.0303 - val_acc: 0.9904\n",
      "Epoch 57/124\n",
      "Epoch 00056: val_loss did not improve\n",
      "13s - loss: 0.0226 - acc: 0.9938 - val_loss: 0.0377 - val_acc: 0.9875\n",
      "Epoch 58/124\n",
      "Epoch 00057: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0218 - acc: 0.9941 - val_loss: 0.0378 - val_acc: 0.9874\n",
      "Epoch 59/124\n",
      "Epoch 00058: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0203 - acc: 0.9943 - val_loss: 0.0384 - val_acc: 0.9875\n",
      "Epoch 60/124\n",
      "Epoch 00059: val_loss improved from 0.03028 to 0.02572, saving model to learn-to-execute-progress-dl\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "15104s - loss: 0.0196 - acc: 0.9944 - val_loss: 0.0257 - val_acc: 0.9923\n",
      "Epoch 61/124\n",
      "Epoch 00060: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0190 - acc: 0.9949 - val_loss: 0.0705 - val_acc: 0.9790\n",
      "Epoch 62/124\n",
      "Epoch 00061: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0210 - acc: 0.9944 - val_loss: 0.0736 - val_acc: 0.9778\n",
      "Epoch 63/124\n",
      "Epoch 00062: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0460 - val_acc: 0.9858\n",
      "Epoch 64/124\n",
      "Epoch 00063: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0209 - acc: 0.9944 - val_loss: 0.0785 - val_acc: 0.9765\n",
      "Epoch 65/124\n",
      "Epoch 00064: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0184 - acc: 0.9952 - val_loss: 0.0728 - val_acc: 0.9798\n",
      "Epoch 66/124\n",
      "Epoch 00065: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0173 - acc: 0.9953 - val_loss: 0.0305 - val_acc: 0.9899\n",
      "Epoch 67/124\n",
      "Epoch 00066: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0169 - acc: 0.9952 - val_loss: 0.1044 - val_acc: 0.9743\n",
      "Epoch 68/124\n",
      "Epoch 00067: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0165 - acc: 0.9952 - val_loss: 0.0554 - val_acc: 0.9815\n",
      "Epoch 69/124\n",
      "Epoch 00068: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0172 - acc: 0.9952 - val_loss: 0.0573 - val_acc: 0.9841\n",
      "Epoch 70/124\n",
      "Epoch 00069: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0165 - acc: 0.9953 - val_loss: 0.0332 - val_acc: 0.9892\n",
      "Epoch 71/124\n",
      "Epoch 00070: val_loss improved from 0.02572 to 0.02404, saving model to learn-to-execute-progress-dl\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0176 - acc: 0.9951 - val_loss: 0.0240 - val_acc: 0.9923\n",
      "Epoch 72/124\n",
      "Epoch 00071: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0153 - acc: 0.9956 - val_loss: 0.0517 - val_acc: 0.9852\n",
      "Epoch 73/124\n",
      "Epoch 00072: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0159 - acc: 0.9953 - val_loss: 0.0262 - val_acc: 0.9914\n",
      "Epoch 74/124\n",
      "Epoch 00073: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0154 - acc: 0.9958 - val_loss: 0.0244 - val_acc: 0.9911\n",
      "Epoch 75/124\n",
      "Epoch 00074: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0157 - acc: 0.9958 - val_loss: 0.0249 - val_acc: 0.9917\n",
      "Epoch 76/124\n",
      "Epoch 00075: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0167 - acc: 0.9956 - val_loss: 0.0298 - val_acc: 0.9909\n",
      "Epoch 77/124\n",
      "Epoch 00076: val_loss improved from 0.02404 to 0.02095, saving model to learn-to-execute-progress-dl\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0156 - acc: 0.9957 - val_loss: 0.0210 - val_acc: 0.9933\n",
      "Epoch 78/124\n",
      "Epoch 00077: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0157 - acc: 0.9959 - val_loss: 0.0294 - val_acc: 0.9895\n",
      "Epoch 79/124\n",
      "Epoch 00078: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0144 - acc: 0.9957 - val_loss: 0.0377 - val_acc: 0.9883\n",
      "Epoch 80/124\n",
      "Epoch 00079: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0142 - acc: 0.9962 - val_loss: 0.0261 - val_acc: 0.9915\n",
      "Epoch 81/124\n",
      "Epoch 00080: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0139 - acc: 0.9962 - val_loss: 0.0258 - val_acc: 0.9914\n",
      "Epoch 82/124\n",
      "Epoch 00081: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0149 - acc: 0.9961 - val_loss: 0.0264 - val_acc: 0.9919\n",
      "Epoch 83/124\n",
      "Epoch 00082: val_loss improved from 0.02095 to 0.01981, saving model to learn-to-execute-progress-dl\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0133 - acc: 0.9963 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 84/124\n",
      "Epoch 00083: val_loss improved from 0.01981 to 0.01852, saving model to learn-to-execute-progress-dl\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0139 - acc: 0.9962 - val_loss: 0.0185 - val_acc: 0.9936\n",
      "Epoch 85/124\n",
      "Epoch 00084: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0135 - acc: 0.9964 - val_loss: 0.0395 - val_acc: 0.9885\n",
      "Epoch 86/124\n",
      "Epoch 00085: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0140 - acc: 0.9963 - val_loss: 0.0276 - val_acc: 0.9904\n",
      "Epoch 87/124\n",
      "Epoch 00086: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0128 - acc: 0.9966 - val_loss: 0.0627 - val_acc: 0.9813\n",
      "Epoch 88/124\n",
      "Epoch 00087: val_loss improved from 0.01852 to 0.01678, saving model to learn-to-execute-progress-dl\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0126 - acc: 0.9964 - val_loss: 0.0168 - val_acc: 0.9949\n",
      "Epoch 89/124\n",
      "Epoch 00088: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0124 - acc: 0.9965 - val_loss: 0.0401 - val_acc: 0.9872\n",
      "Epoch 90/124\n",
      "Epoch 00089: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0127 - acc: 0.9966 - val_loss: 0.0263 - val_acc: 0.9921\n",
      "Epoch 91/124\n",
      "Epoch 00090: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0347 - val_acc: 0.9887\n",
      "Epoch 92/124\n",
      "Epoch 00091: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0131 - acc: 0.9965 - val_loss: 0.0513 - val_acc: 0.9847\n",
      "Epoch 93/124\n",
      "Epoch 00092: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0257 - val_acc: 0.9912\n",
      "Epoch 94/124\n",
      "Epoch 00093: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0121 - acc: 0.9968 - val_loss: 0.0216 - val_acc: 0.9929\n",
      "Epoch 95/124\n",
      "Epoch 00094: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0128 - acc: 0.9965 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 96/124\n",
      "Epoch 00095: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "13s - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0184 - val_acc: 0.9940\n",
      "Epoch 97/124\n",
      "Epoch 00096: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0113 - acc: 0.9968 - val_loss: 0.0194 - val_acc: 0.9935\n",
      "Epoch 98/124\n",
      "Epoch 00097: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0107 - acc: 0.9970 - val_loss: 0.0298 - val_acc: 0.9891\n",
      "Epoch 99/124\n",
      "Epoch 00098: early stopping\n",
      "Epoch 00098: val_loss did not improve\n",
      "Warning: could not reach RemoteMonitor root server at http://localhost:9000\n",
      "14s - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0170 - val_acc: 0.9941\n"
     ]
    }
   ],
   "source": [
    "# compile and run\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "result = model.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          nb_epoch=124,\n",
    "          validation_data=(X_val, y_val),\n",
    "          verbose=2,\n",
    "          callbacks = [\n",
    "                         EarlyStopping(verbose=True, patience=10, monitor='val_loss'),\n",
    "                         ModelCheckpoint('{}-progress-dl'.format(\"learn-to-execute\"), monitor='val_loss', verbose=True, save_best_only=True), remote],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End at 99 epoch\n"
     ]
    }
   ],
   "source": [
    "nb_end_epoch = len(result.history['acc'])\n",
    "print(\"End at {} epoch\".format(nb_end_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = \"learn-to-execute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test score: 0.0167780931439\n",
      "Test accuracy: 0.99485\n"
     ]
    }
   ],
   "source": [
    "# -- load in best network\n",
    "model.load_weights('{}-progress-dl'.format(TARGET_NAME))\n",
    "score = model.evaluate(X_val, y_val, verbose=0)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.visualize_util import model_to_dot, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAEWCAYAAABc9SIZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115c5ff10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(nb_end_epoch)\n",
    "fix, ax = plt.subplots(figsize=(10, 4))\n",
    "plt.suptitle('Loss and Accuracy GRU')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, result.history['acc'], label=\"train acc\")\n",
    "plt.plot(x, result.history['val_acc'], label=\"val acc\")\n",
    "plt.legend(loc='best', bbox_to_anchor=(1, 0.5))\n",
    "plt.title(\"Accuracy plot\");\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, result.history['loss'], label=\"train loss\")\n",
    "plt.plot(x, result.history['val_loss'], label=\"val loss\")\n",
    "plt.legend(loc='best', bbox_to_anchor=(1,0.5))\n",
    "plt.title(\"Loss plot\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "from keras.models import model_from_json, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "gru_3 (GRU)                      (None, 128)           54144       gru_input_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_2 (RepeatVector)    (None, 4, 128)        0           gru_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 4, 128)        98688       repeatvector_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribute(None, 4, 12)         1548        gru_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4, 12)         0           timedistributed_2[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 154380\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./{}.h5\".format(TARGET_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 85+442 \n",
      "T 527 \n",
      "\u001b[92m☑\u001b[0m 527 \n",
      "---\n",
      "Q 940+0  \n",
      "T 940 \n",
      "\u001b[92m☑\u001b[0m 940 \n",
      "---\n",
      "Q 816+5  \n",
      "T 821 \n",
      "\u001b[92m☑\u001b[0m 821 \n",
      "---\n",
      "Q 66+506 \n",
      "T 572 \n",
      "\u001b[92m☑\u001b[0m 572 \n",
      "---\n",
      "Q 859+434\n",
      "T 1293\n",
      "\u001b[92m☑\u001b[0m 1293\n",
      "---\n",
      "Q 99+916 \n",
      "T 1015\n",
      "\u001b[92m☑\u001b[0m 1015\n",
      "---\n",
      "Q 720+9  \n",
      "T 729 \n",
      "\u001b[92m☑\u001b[0m 729 \n",
      "---\n",
      "Q 152+7  \n",
      "T 159 \n",
      "\u001b[92m☑\u001b[0m 159 \n",
      "---\n",
      "Q 542+85 \n",
      "T 627 \n",
      "\u001b[92m☑\u001b[0m 627 \n",
      "---\n",
      "Q 8+454  \n",
      "T 462 \n",
      "\u001b[92m☑\u001b[0m 462 \n",
      "---\n",
      "CPU times: user 1.53 s, sys: 403 ms, total: 1.94 s\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#For predicting the outputs, the predict method will return \n",
    "#an one hot encoded ouput, we decode the one hot encoded \n",
    "#ouptut to get our final output\n",
    "\n",
    "# Select 10 samples from the validation set at random so we can visualize errors\n",
    "for i in range(10):\n",
    "    ind = np.random.randint(0, len(X_val))\n",
    "    rowX, rowy = X_val[np.array([ind])], y_val[np.array([ind])]\n",
    "    preds = model.predict_classes(rowX, verbose=0)\n",
    "    q = ctable.decode(rowX[0])\n",
    "    correct = ctable.decode(rowy[0])\n",
    "    guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "    print('Q', q[::-1] if INVERT else q)\n",
    "    print('T', correct)\n",
    "    print(colors.ok + '☑' + colors.close if correct == guess else colors.fail + '☒' + colors.close, guess)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 123+897\n",
      "T 1020\n",
      "\u001b[92m☑\u001b[0m 1020\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# kindergarten\n",
    "q='1+1'\n",
    "a='2'\n",
    "\n",
    "# primary school\n",
    "q='23+75'\n",
    "a='98'\n",
    "\n",
    "# high school\n",
    "q='127+249'\n",
    "a='376'\n",
    "\n",
    "# university\n",
    "q='123+897'\n",
    "a='1020'\n",
    "\n",
    "xq = ctable.encode(\"{:7s}\".format(q), maxlen=MAXLEN)\n",
    "xa = ctable.encode(\"{:4s}\".format(a), maxlen=MAXLEN+1)\n",
    "\n",
    "preds = model.predict_classes(np.asarray([xq]), verbose=0)\n",
    "guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "print('Q', q)\n",
    "print('T', a)\n",
    "print(colors.ok + '☑' + colors.close if a.strip() == guess.strip() else colors.fail + '☒' + colors.close, guess)\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def fix_math(q, model=model):\n",
    "    xq = re.findall(r'\\d+\\+\\d+', q)\n",
    "    if xq:\n",
    "        xq = xq[0]\n",
    "        xq = ctable.encode(\"{:7s}\".format(q), maxlen=MAXLEN)\n",
    "        preds = model.predict_classes(np.asarray([xq]), verbose=0)\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        return u\"👻 \\033[35mI guess: \" + guess.strip() + \"\\033[0m\"\n",
    "    else:\n",
    "        return u\"👻 \\033[91mGive me correct summation, LOL!!!\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fix_math(\"12+23\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fix_math(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
